from pymongo import MongoClient
from langchain_community.vectorstores import MongoDBAtlasVectorSearch
from langchain_community.docstore.document import Document
from langchain_core.embeddings import Embeddings
from langchain.chains import RetrievalQA
import google.generativeai as genai
import gradio as gr
from gradio.themes.base import Base
import key_param

# Set up Google API
genai.configure(api_key=key_param.google_api_key)

# Custom Embedding class
class CustomEmbedding(Embeddings):
    def embed_documents(self, texts):
        return [self.embed_query(text) for text in texts]

    def embed_query(self, text):
        result = genai.embed_content(
            model="models/embedding-001",
            content=text,
            task_type="retrieval_document",
            title="Embedding of text"
        )
        return result['embedding']

client = MongoClient(key_param.MONGO_URI)
dbName = "langchain_demo"
collectionName = "collection_of_text_blobs"
collection = client[dbName][collectionName]

# Initialize the custom embedding
custom_embeddings = CustomEmbedding()

# Initialize the Vector Store
vectorStore = MongoDBAtlasVectorSearch(
    collection=collection,
    embedding=custom_embeddings
)

def query_data(query):
    # import pdb
    # pdb.set_trace()
    # Perform Atlas Vector Search using Langchain's vectorStore
    # Define the Gemini LLM
    model = genai.GenerativeModel('gemini-pro')

    # Get VectorStoreRetriever
    retriever = vectorStore.as_retriever()

    # Custom QA function using Gemini
    def qa_function(query):
        context = retriever.get_relevant_documents(query)
        context_text = "\n".join([doc.page_content for doc in context])
        prompt = f"Context: {context_text}\n\nQuestion: {query}\n\nAnswer:"
        response = model.generate_content(prompt)
        return response.text

    # Execute the QA function
    retriever_output = qa_function(query)

    # Return only the output generated using RAG Architecture
    return retriever_output

# Create a web interface for the app, using Gradio
with gr.Blocks(theme=Base(), title="Question Answering App using Vector Search + RAG") as demo:
    gr.Markdown(
        """
        # Question Answering App using Atlas Vector Search + RAG Architecture (with Gemini)
        """)
    textbox = gr.Textbox(label="Enter your Question:")
    with gr.Row():
        button = gr.Button("Submit", variant="primary")
    output = gr.Textbox(lines=1, max_lines=10, label="Output generated by chaining Atlas Vector Search to Gemini LLM:")

    # Call query_data function upon clicking the Submit button
    button.click(query_data, textbox, outputs=output)

demo.launch()
